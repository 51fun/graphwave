{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Using GraphWave </h1> </center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "The goal of the  following notebook is to show how the GraphWave algorithm can be used. \n",
    "\n",
    "GraphWave was implemented in Python 2.7 and requires to load the following Python packages:\n",
    "\n",
    "+ __pygsp__ (Graph signal Processing package from EPFL, to compute spectral graph wavelets.)\n",
    "+ __networkx__ (for handling network objects: in particular, visualization, etc.)\n",
    "+ traditional libraries for data analytics: __seaborn__ for plotting, __pandas__ for dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from graphwave.shapes import build_graph\n",
    "from graphwave.graphwave import *\n",
    "\n",
    "\n",
    "np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## I. Creating a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1- Start by defining our favorite regular structure\n",
    "\n",
    "filename_graph_indic=\"/Users/cdonnat/Downloads/Wiki-Vote.txt\"\n",
    "edge_list=[]\n",
    "with open(filename_graph_indic) as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        line=line.strip(\"\\n\")\n",
    "        line=line.strip(\"\\r\")\n",
    "        if i > 5:\n",
    "            line = line.split('\\t')\n",
    "            edge_list += [[int(line[0]),int(line[1])]]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = nx.from_edgelist(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100760"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function number_connected_components in module networkx.algorithms.components.connected:\n",
      "\n",
      "number_connected_components(G)\n",
      "    Return the number of connected components.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    G : NetworkX graph\n",
      "       An undirected graph.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    n : integer\n",
      "       Number of connected components\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    connected_components\n",
      "    number_weakly_connected_components\n",
      "    number_strongly_connected_components\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    For undirected graphs only.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nx.number_connected_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_connected_components(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7066)\n",
      "(1, 2)\n",
      "(2, 2)\n",
      "(3, 2)\n",
      "(4, 2)\n",
      "(5, 2)\n",
      "(6, 2)\n",
      "(7, 2)\n",
      "(8, 2)\n",
      "(9, 2)\n",
      "(10, 2)\n",
      "(11, 2)\n",
      "(12, 2)\n",
      "(13, 2)\n",
      "(14, 2)\n",
      "(15, 3)\n",
      "(16, 2)\n",
      "(17, 2)\n",
      "(18, 3)\n",
      "(19, 2)\n",
      "(20, 2)\n",
      "(21, 2)\n",
      "(22, 2)\n",
      "(23, 3)\n"
     ]
    }
   ],
   "source": [
    "conn_comp={}\n",
    "it_g = 0\n",
    "for g in nx.connected_component_subgraphs(graph):\n",
    "    conn_comp[it_g] = g\n",
    "    print(it_g, g.number_of_nodes())\n",
    "    it_g += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taus = list(np.arange(0.5, 3.0, 0.2))+list(range(3, 5))\n",
    "# Compute the optimal embedding\n",
    "pygsp_graph = pygsp.graphs.Graph(nx.adjacency_matrix(conn_comp[0]),\n",
    "                                 lap_type='normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7066x7066 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 208534 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pygsp_graph.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pygsp_graph.connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pygsp_graph.compute_fourier_basis(recompute=True)\n",
    "# safety check to ensure that the graph is indeed connected\n",
    "l1 = sc.sparse.linalg.eigsh(pygsp_graph.L, k=2, which='SM')[0][1]\n",
    "smax = -np.log(0.75) * np.sqrt(2.0 / l1)\n",
    "smin = -np.log(0.90) * np.sqrt(2.0/ l1)\n",
    "taus = list(np.linspace(smin,smax,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "tic=time.time()\n",
    "diff_type = 'heat'\n",
    "n_nodes = pygsp_graph.N\n",
    "if True:\n",
    "    n_filters = len(taus)\n",
    "\n",
    "    if diff_type == 'mexican':\n",
    "        n_filters = 6\n",
    "        Hk = pygsp.filters.MexicanHat(pygsp_graph, n_filters)\n",
    "    elif diff_type == 'wave':\n",
    "        Hk = pygsp.filters.Wave(pygsp_graph, taus, normalize=True)\n",
    "    else:\n",
    "        Hk = pygsp.filters.Heat(pygsp_graph, taus, normalize=False)\n",
    "\n",
    "heat = {tau: sc.sparse.csc_matrix(( n_nodes, n_nodes)) for tau in taus}\n",
    "Sf_vec = Hk.analysis(np.eye(n_nodes), cheb_order = 10)\n",
    "toc =time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Then we need to convert them into an adequate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Heat in module pygsp.filters.heat object:\n",
      "\n",
      "class Heat(pygsp.filters.filter.Filter)\n",
      " |  Heat Filterbank\n",
      " |  \n",
      " |  Inherits its methods from Filters\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  G : Graph\n",
      " |  tau : int or list of ints\n",
      " |      Scaling parameter. (default = 10)\n",
      " |  normalize : bool\n",
      " |      Normalize the kernel (works only if the eigenvalues are\n",
      " |      present in the graph). (default = 0)\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  out : Heat\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from pygsp import graphs, filters\n",
      " |  >>> G = graphs.Logo()\n",
      " |  >>> F = filters.Heat(G)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Heat\n",
      " |      pygsp.filters.filter.Filter\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, G, tau=10, normalize=False, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pygsp.filters.filter.Filter:\n",
      " |  \n",
      " |  analysis(self, s, method=None, cheb_order=30, lanczos_order=30, **kwargs)\n",
      " |      Operator to analyse a filterbank\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      s : ndarray\n",
      " |          graph signals to analyse\n",
      " |      method : string\n",
      " |          wether using an exact method, cheby approx or lanczos\n",
      " |      cheb_order : int\n",
      " |          Order for chebyshev\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      c : ndarray\n",
      " |          Transform coefficients\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> from pygsp import graphs, filters\n",
      " |      >>> G = graphs.Logo()\n",
      " |      >>> MH = filters.MexicanHat(G)\n",
      " |      >>> x = np.arange(G.N**2).reshape(G.N, G.N)\n",
      " |      >>> co = MH.analysis(x)\n",
      " |      \n",
      " |      :cite:`hammond2011wavelets`\n",
      " |  \n",
      " |  approx(m, N, **kwargs)\n",
      " |  \n",
      " |  can_dual(self)\n",
      " |      Creates a dual graph form a given graph\n",
      " |  \n",
      " |  evaluate = inner(f, *args, **kwargs)\n",
      " |  \n",
      " |  filterbank_bounds(self, N=999, bounds=None)\n",
      " |      Compute approximate frame bounds for a filterbank.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bounds : interval to compute the bound.\n",
      " |          Given in an ndarray: np.array([xmin, xnmax]).\n",
      " |          By default, bounds is None and filtering is bounded\n",
      " |          by the eigenvalues of G.\n",
      " |      N : Number of point for the line search\n",
      " |          Default is 999\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      lower : Filterbank lower bound\n",
      " |      upper : Filterbank upper bound\n",
      " |  \n",
      " |  filterbank_matrix(self)\n",
      " |      Create the matrix of the filterbank frame.\n",
      " |      \n",
      " |      This function creates the matrix associated to the filterbank g.\n",
      " |      The size of the matrix is MN x N, where M is the number of filters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      F : Frame\n",
      " |  \n",
      " |  inverse(self, c, **kwargs)\n",
      " |  \n",
      " |  plot(self, **kwargs)\n",
      " |      Plot the filter.\n",
      " |      \n",
      " |      See plotting doc.\n",
      " |  \n",
      " |  synthesis(self, c, order=30, method=None, **kwargs)\n",
      " |      Synthesis operator of a filterbank\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      G : Graph structure.\n",
      " |      c : Transform coefficients\n",
      " |      method : Select the method ot be used for the computation.\n",
      " |          - 'exact' : Exact method using the graph Fourier matrix\n",
      " |          - 'cheby' : Chebyshev polynomial approximation\n",
      " |          - 'lanczos' : Lanczos approximation\n",
      " |      \n",
      " |          Default : if the Fourier matrix is present: 'exact' otherwise\n",
      " |          'cheby'\n",
      " |      order : Degree of the Chebyshev approximation\n",
      " |          Default is 30\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      signal : sythesis signal\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Reference\n",
      " |      ----------\n",
      " |      See :cite:`hammond2011wavelets` for more details.\n",
      " |  \n",
      " |  tighten()\n",
      " |  \n",
      " |  wlog_scales(self, lmin, lmax, Nscales, t1=1, t2=2)\n",
      " |      Compute logarithm scales for wavelets\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lmin : int\n",
      " |          Minimum non-zero eigenvalue\n",
      " |      lmax : int\n",
      " |          Maximum eigenvalue\n",
      " |      Nscales : int\n",
      " |          Number of scales\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      s : ndarray\n",
      " |          Scale\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pygsp.filters.filter.Filter:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Hk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_filters):\n",
    "        heat[taus[i]]= sc.sparse.csc_matrix(Sf_vec[i * n_nodes: (i + 1) * n_nodes, :] )    # stores in tensor the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  7.83515091e-01],\n",
       "        [  7.34737288e-05],\n",
       "        [  5.90369948e-05],\n",
       "        ..., \n",
       "        [  1.19696857e-07],\n",
       "        [  7.96622698e-09],\n",
       "        [  2.41718737e-08]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(heat[taus[9]][:,0].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49928356"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7066 * 7066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: best visualization of the graphs are obtained using Gephi, or some other specialized graph visualization software)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Running GraphWave\n",
    "\n",
    "\n",
    "We propose here a simple demonstration of GraphWave using both the automatic version (part a) and the manual version. This shows how to use GraphWave in a parameter-free version, or giving the analyst the possibility to select an adequate scale value.\n",
    "\n",
    "For each of these approaches, we compute the signature by calling GraphWave. We then compute its PCA projection to visualize the embeddings. Note that in this very simple examples, GraphWave recovers structura equivalence, as shown by the overlapping embeddings on the first principal components.\n",
    "\n",
    "#### a. Multiscale GraphWave: Automatic selection of the range of scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chi, heat_print, taus = graphwave(graph, taus='automatic_large_matrix', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualize the resulting embeddings by computing their PCA projections. We also run KMeans to assess how well the signatures that we have here generated enable the recovery of structural roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_clust = len(np.unique(role_id))\n",
    "pca = PCA(n_components=5)\n",
    "trans_data = pca.fit_transform(StandardScaler().fit_transform(chi))\n",
    "km = KMeans(n_clusters=nb_clust)\n",
    "km.fit(trans_data)\n",
    "labels_pred=km.labels_\n",
    "\n",
    "######## Params for plotting\n",
    "cmapx=plt.get_cmap('rainbow')\n",
    "x=np.linspace(0,1,nb_clust+1)\n",
    "col=[cmapx(xx) for xx in x ]\n",
    "markers = {0:'*',1: '.', 2:',',3: 'o',4: 'v',5: '^',6: '<',7: '>',8: 3 ,9:'d',10: '+',11:'x',12:'D',13: '|',14: '_',15:4,16:0,17:1,18:2,19:6,20:7}\n",
    "\n",
    "for c in np.unique(role_id):\n",
    "    indc = [i for i,x in enumerate(role_id) if x==c]\n",
    "    plt.scatter(trans_data[indc,0], trans_data[indc,1],\n",
    "                c=np.array(col)[list(np.array(labels_pred)[indc])],\n",
    "                marker=markers[c%len(markers)], s=300)\n",
    "\n",
    "labels = role_id\n",
    "for label,c, x, y in zip(labels,labels_pred, trans_data[:, 0], trans_data[:, 1]):\n",
    "            plt.annotate(label,xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniscale GraphWave: Hand-selected value for tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Select a scale of interest (here we select a particular range of scale. See associated paper for \n",
    "### guidelines on how to select the appropriate scale.)\n",
    "\n",
    "### Compute the heat wavelet\n",
    "from graphwave.graphwave import *\n",
    "\n",
    "time_pts = list(np.arange(0,50,0.5))\n",
    "chi,heat_print, taus=graphwave(G, taus = [0.5], time_pts=time_pts, verbose=False)\n",
    "print(chi.shape, len(time_pts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the EPFL implementation, by construction, the wavelet scales are all divided by the maximum eigenvalue $\\lambda_N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_clust=len(np.unique(role_id))\n",
    "pca=PCA(n_components=5)\n",
    "trans_data=pca.fit_transform(StandardScaler().fit_transform(chi))\n",
    "km=KMeans(n_clusters=nb_clust)\n",
    "km.fit(trans_data)\n",
    "labels_pred=km.labels_\n",
    "\n",
    "\n",
    "cmapx=plt.get_cmap('rainbow')\n",
    "x=np.linspace(0,1,np.max(labels_pred)+1)\n",
    "col=[cmapx(xx) for xx in x ]\n",
    "markers = {0:'*',1: '.', 2:',',3: 'o',4: 'v',5: '^',6: '<',7: '>',8: 3 ,9:'d',10: '+',11:'x',12:'D',13: '|',14: '_',15:4,16:0,17:1,18:2,19:6,20:7}\n",
    "\n",
    "\n",
    "for c in np.unique(role_id):\n",
    "        indc=[i for i,x in enumerate(role_id) if x==c]\n",
    "        _ = plt.scatter(trans_data[indc,0], trans_data[indc,1],c=np.array(col)[list(np.array(labels_pred)[indc])] ,marker=markers[c%len(markers)],s=500)\n",
    "\n",
    "labels = role_id\n",
    "for label,c, x, y in zip(labels,labels_pred, trans_data[:, 0], trans_data[:, 1]):\n",
    "            _ = plt.annotate(label,xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Visualizing the Characteristic functions\n",
    "\n",
    "We now propose to show how to visualize characteristic functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapping = {u: i for i,u in enumerate(np.unique(role_id))}\n",
    "cmap=plt.get_cmap('gnuplot')\n",
    "role_id_plot=[cmap(x) for x in np.linspace(0,1,len(np.unique(role_id)))]\n",
    "plt.figure()\n",
    "ind_x=range(chi[0].shape[0])[0::2]\n",
    "ind_y=range(chi[0].shape[0])[1::2]\n",
    "for i in np.random.choice(range(G.number_of_nodes()),10,replace=False):\n",
    "    _ = plt.plot(chi[i,ind_x],chi[i,ind_y],label=str(i),color=role_id_plot[mapping[role_id[i]]])\n",
    "\n",
    "_ = plt.legend(loc='center left',bbox_to_anchor=(1,0.5))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
