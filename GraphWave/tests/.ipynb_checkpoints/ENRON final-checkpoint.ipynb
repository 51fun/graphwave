{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> ENRON email dataset </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here test GraphWave against RoleX and struc2vec on a real life dataset: the Enron email dataset. The data consists of the graph measuring email exchange frequencies between 184 people in the company. We also have access to the job title of these employees, which we will take as \"ground-truth labels\" in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import networkx as nx \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sys\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "####\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "####\n",
    "sys.path.append( '../../GraphWave/')\n",
    "from distances.distances_signature import *\n",
    "from graphwave import *\n",
    "import utils.graph_tools \n",
    "from utils.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load the data and create the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Load the data and create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albert.meyers', 'Albert Meyers       Employee           Specialist']\n",
      "['Albert', 'Meyers', 'Employee', 'Specialist']\n",
      "Albert Meyers\n",
      "Employee Specialist\n",
      "['a..martin', 'Thomas Martin           Vice President']\n",
      "['Thomas', 'Martin', 'Vice', 'President']\n",
      "Thomas Martin\n",
      "Vice President\n",
      "['andrea.ring', 'Andrea Ring         N/A']\n",
      "['Andrea', 'Ring', 'N/A']\n",
      "Andrea Ring\n",
      "N/A\n",
      "['andrew.lewis', 'Andrew Lewis            Director']\n",
      "['Andrew', 'Lewis', 'Director']\n",
      "Andrew Lewis\n",
      "Director\n",
      "['andy.zipper', 'Andy Zipper            Vice President     Enron Online']\n",
      "['Andy', 'Zipper', 'Vice', 'President', 'Enron', 'Online']\n",
      "Andy Zipper\n",
      "Vice President Enron Online\n",
      "['a..shankman', 'Jeffrey Shankman       President          Enron Global Mkts']\n",
      "['Jeffrey', 'Shankman', 'President', 'Enron', 'Global', 'Mkts']\n",
      "Jeffrey Shankman\n",
      "President Enron Global Mkts\n",
      "['barry.tycholiz', 'Barry Tycholiz          Vice President']\n",
      "['Barry', 'Tycholiz', 'Vice', 'President']\n",
      "Barry Tycholiz\n",
      "Vice President\n",
      "['benjamin.rogers', 'Benjamin Rogers        Employee           Associate']\n",
      "['Benjamin', 'Rogers', 'Employee', 'Associate']\n",
      "Benjamin Rogers\n",
      "Employee Associate\n",
      "['bill.rapp', 'Bill Rapp              N/A']\n",
      "['Bill', 'Rapp', 'N/A']\n",
      "Bill Rapp\n",
      "N/A\n",
      "['bill.williams', 'xxx']\n",
      "['xxx']\n",
      "['Bradley', 'Mckay', 'Employee']\n",
      "Bradley Mckay\n",
      "Employee\n",
      "['xxx']\n",
      "['Richard', 'Sanders', 'Vice', 'President', 'Enron', 'WholeSale', 'Services']\n",
      "Richard Sanders\n",
      "Vice President Enron WholeSale Services\n",
      "['Cara', 'Semperger', 'Employee', 'Senior', 'Analyst', 'Cash']\n",
      "Cara Semperger\n",
      "Employee Senior Analyst Cash\n",
      "['Daron', 'Giron', 'Employee']\n",
      "Daron Giron\n",
      "Employee\n",
      "['Charles', 'Weldon', 'N/A']\n",
      "Charles Weldon\n",
      "N/A\n",
      "['Chris', 'Dorland', 'Manager']\n",
      "Chris Dorland\n",
      "Manager\n",
      "['Chris', 'Germany', 'Employee']\n",
      "Chris Germany\n",
      "Employee\n",
      "['xxx']\n",
      "['Cooper', 'Richey', 'Manager']\n",
      "Cooper Richey\n",
      "Manager\n",
      "['Craig', 'Dean', 'Trader']\n",
      "Craig Dean\n",
      "Trader\n",
      "['Dana', 'Davis', 'Vice', 'President', 'Term']\n",
      "Dana Davis\n",
      "Vice President Term\n",
      "['Dan', 'Hyvl', 'Employee']\n",
      "Dan Hyvl\n",
      "Employee\n",
      "['Danny', 'McCarty', 'Vice', 'President']\n",
      "Danny McCarty\n",
      "Vice President\n",
      "['Daren', 'Farmer', 'Manager', 'Logistics', 'Manager']\n",
      "Daren Farmer\n",
      "Manager Logistics Manager\n",
      "['Darrell', 'Schoolcraft', 'N/A']\n",
      "Darrell Schoolcraft\n",
      "N/A\n",
      "['Daron', 'Giron', 'Employee']\n",
      "Daron Giron\n",
      "Employee\n",
      "['David', 'Delainey', 'CEO', 'Enron', 'North', 'America', 'and', 'Enron', 'Enery', 'Services']\n",
      "David Delainey\n",
      "CEO Enron North America and Enron Enery Services\n",
      "['Susan', 'Bailey', 'N/A']\n",
      "Susan Bailey\n",
      "N/A\n",
      "['xxx']\n",
      "['Diana', 'Scholtes', 'Trader']\n",
      "Diana Scholtes\n",
      "Trader\n",
      "['Thomas', 'Martin', 'Vice', 'President']\n",
      "Thomas Martin\n",
      "Vice President\n",
      "['Don', 'Baughman', 'Trader']\n",
      "Don Baughman\n",
      "Trader\n",
      "['Drew', 'Fossum', 'Vice', 'President']\n",
      "Drew Fossum\n",
      "Vice President\n",
      "['James', 'Steffes', 'Vice', 'President', 'Government', 'Affairs']\n",
      "James Steffes\n",
      "Vice President Government Affairs\n",
      "['xxx']\n",
      "['xxx']\n",
      "['Mark', 'Haedicke', 'Managing', 'Director', 'Legal', 'Department']\n",
      "Mark Haedicke\n",
      "Managing Director Legal Department\n",
      "['Elizabeth', 'Sager', 'Employee']\n",
      "Elizabeth Sager\n",
      "Employee\n",
      "['Eric', 'Bass', 'Trader']\n",
      "Eric Bass\n",
      "Trader\n",
      "['Eric', 'Saibi', 'Trader']\n",
      "Eric Saibi\n",
      "Trader\n",
      "['Errol', 'McLaughlin', 'Employee']\n",
      "Errol McLaughlin\n",
      "Employee\n",
      "['Mark', 'Taylor', 'Employee']\n",
      "Mark Taylor\n",
      "Employee\n",
      "['Sandra', 'Brawner', 'Director']\n",
      "Sandra Brawner\n",
      "Director\n",
      "['Larry', 'Campbell', 'Employee', 'Senior', 'Specialist']\n",
      "Larry Campbell\n",
      "Employee Senior Specialist\n",
      "['Peter', 'Keavey', 'Employee']\n",
      "Peter Keavey\n",
      "Employee\n",
      "['Fletcher', 'Sturm', 'Vice', 'President']\n",
      "Fletcher Sturm\n",
      "Vice President\n",
      "['Frank', 'Ermis', 'Director']\n",
      "Frank Ermis\n",
      "Director\n",
      "['Geir', 'Solberg', 'Employee', 'Analyst']\n",
      "Geir Solberg\n",
      "Employee Analyst\n",
      "['Geoffery', 'Storey', 'Director']\n",
      "Geoffery Storey\n",
      "Director\n",
      "['Gerald', 'Nemec', 'N/A']\n",
      "Gerald Nemec\n",
      "N/A\n",
      "['Greg', 'Whalley', 'President']\n",
      "Greg Whalley\n",
      "President\n",
      "['xxx']\n",
      "['Harpreet', 'Arora', 'Vice', 'President']\n",
      "Harpreet Arora\n",
      "Vice President\n",
      "['Andrew', 'Lewis', 'Director']\n",
      "Andrew Lewis\n",
      "Director\n",
      "['Holden', 'Salisbury', 'Employee', 'Cash', 'Analyst']\n",
      "Holden Salisbury\n",
      "Employee Cash Analyst\n",
      "['Hunter', 'Shively', 'Vice', 'President']\n",
      "Hunter Shively\n",
      "Vice President\n",
      "['James', 'Derrick', 'In', 'House', 'Lawyer']\n",
      "James Derrick\n",
      "In House Lawyer\n",
      "['James', 'Steffes', 'Vice', 'President', 'Government', 'Affairs']\n",
      "James Steffes\n",
      "Vice President Government Affairs\n",
      "['Jane', 'Tholt', 'Vice', 'President']\n",
      "Jane Tholt\n",
      "Vice President\n",
      "['xxx']\n",
      "['Jason', 'Wolfe', 'N/A']\n",
      "Jason Wolfe\n",
      "N/A\n",
      "['Jay', 'Reitmeyer', 'Employee']\n",
      "Jay Reitmeyer\n",
      "Employee\n",
      "['Jeff', 'Dasovich', 'Employee', 'Government', 'Relation', 'Executive']\n",
      "Jeff Dasovich\n",
      "Employee Government Relation Executive\n",
      "['Jeff', 'King', 'Manager']\n",
      "Jeff King\n",
      "Manager\n",
      "['John', 'Hodge', 'Managing', 'Director']\n",
      "John Hodge\n",
      "Managing Director\n",
      "['Jeffrey', 'Shankman', 'President', 'Enron', 'Global', 'Mkts']\n",
      "Jeffrey Shankman\n",
      "President Enron Global Mkts\n",
      "['Jeffery', 'Skilling', 'CEO']\n",
      "Jeffery Skilling\n",
      "CEO\n",
      "['Daren', 'Farmer', 'Manager', 'Logistics', 'Manager']\n",
      "Daren Farmer\n",
      "Manager Logistics Manager\n",
      "['xxx']\n",
      "['Jim', 'Schwieger', 'Trader']\n",
      "Jim Schwieger\n",
      "Trader\n",
      "['Vince', 'Kaminski', 'Manager', 'Risk', 'Management', 'Head']\n",
      "Vince Kaminski\n",
      "Manager Risk Management Head\n",
      "['Vince', 'Kaminski', 'Manager', 'Risk', 'Management', 'Head']\n",
      "Vince Kaminski\n",
      "Manager Risk Management Head\n",
      "['Steven', 'Kean', 'Vice', 'President', 'Vice', 'President', '&', 'Chief', 'of', 'Staff']\n",
      "Steven Kean\n",
      "Vice President Vice President & Chief of Staff\n",
      "['xxx']\n",
      "['Joe', 'Parks', 'N/A']\n",
      "Joe Parks\n",
      "N/A\n",
      "['Joe', 'Quenet', 'Trader']\n",
      "Joe Quenet\n",
      "Trader\n",
      "['Joe', 'Stepenovitch', 'Vice', 'President', 'Enery', 'marketting', 'and', 'trading', 'Florida']\n",
      "Joe Stepenovitch\n",
      "Vice President Enery marketting and trading Florida\n",
      "['John', 'Arnold', 'Vice', 'President']\n",
      "John Arnold\n",
      "Vice President\n",
      "['John', 'Forney', 'Manager', 'Real', 'time', 'Trading', 'Desk']\n",
      "John Forney\n",
      "Manager Real time Trading Desk\n",
      "['xxx']\n",
      "['John', 'Hodge', 'Managing', 'Director']\n",
      "John Hodge\n",
      "Managing Director\n",
      "['John', 'Lavorato', 'CEO', 'Enron', 'America']\n",
      "John Lavorato\n",
      "CEO Enron America\n",
      "['John', 'Zufferli', 'Vice', 'President']\n",
      "John Zufferli\n",
      "Vice President\n",
      "['Jonathan', 'Mckay', 'Director']\n",
      "Jonathan Mckay\n",
      "Director\n",
      "['Fletcher', 'Sturm', 'Vice', 'President']\n",
      "Fletcher Sturm\n",
      "Vice President\n",
      "['Juan', 'Hernandez', 'Employee', 'Senior', 'Specialist', 'Logistics']\n",
      "Juan Hernandez\n",
      "Employee Senior Specialist Logistics\n",
      "['xxx']\n",
      "['Judy', 'Townsend', 'Employee']\n",
      "Judy Townsend\n",
      "Employee\n",
      "['Philip', 'Allen', 'Manager']\n",
      "Philip Allen\n",
      "Manager\n",
      "['Kam', 'Keiser', 'Employee']\n",
      "Kam Keiser\n",
      "Employee\n",
      "['Kate', 'Symes', 'Employee']\n",
      "Kate Symes\n",
      "Employee\n",
      "['Kay', 'Mann', 'Employee']\n",
      "Kay Mann\n",
      "Employee\n",
      "['Keith', 'Holst', 'Director']\n",
      "Keith Holst\n",
      "Director\n",
      "['Kenneth', 'Lay', 'CEO']\n",
      "Kenneth Lay\n",
      "CEO\n",
      "['Kevin', 'Hyatt', 'Director', 'Pipeline', 'Business']\n",
      "Kevin Hyatt\n",
      "Director Pipeline Business\n",
      "['Kevin', 'Presto', 'Vice', 'President']\n",
      "Kevin Presto\n",
      "Vice President\n",
      "['Kevin', 'Ruscitti', 'Trader']\n",
      "Kevin Ruscitti\n",
      "Trader\n",
      "['Kimberly', 'Watson', 'N/A']\n",
      "Kimberly Watson\n",
      "N/A\n",
      "['Kim', 'Ward', 'N/A']\n",
      "Kim Ward\n",
      "N/A\n",
      "['Larry', 'Campbell', 'Employee', 'Senior', 'Specialist']\n",
      "Larry Campbell\n",
      "Employee Senior Specialist\n",
      "['Lawrence', 'May', 'Director']\n",
      "Lawrence May\n",
      "Director\n",
      "['Randall', 'Gay', 'N/A']\n",
      "Randall Gay\n",
      "N/A\n",
      "['Lindy', 'Donoho', 'Employee']\n",
      "Lindy Donoho\n",
      "Employee\n",
      "['xxx']\n",
      "['xxx']\n",
      "['Patrice', 'Mims', 'N/A']\n",
      "Patrice Mims\n",
      "N/A\n",
      "['Louise', 'Kitchen', 'President', 'Enron', 'Online']\n",
      "Louise Kitchen\n",
      "President Enron Online\n",
      "['Lynn', 'Blair', 'N/A']\n",
      "Lynn Blair\n",
      "N/A\n",
      "['xxx']\n",
      "['Marie', 'Heard', 'N/A']\n",
      "Marie Heard\n",
      "N/A\n",
      "['Mark', 'Haedicke', 'Managing', 'Director', 'Legal', 'Department']\n",
      "Mark Haedicke\n",
      "Managing Director Legal Department\n",
      "['Mark', 'Haedicke', 'Managing', 'Director', 'Legal', 'Department']\n",
      "Mark Haedicke\n",
      "Managing Director Legal Department\n",
      "['xxx']\n",
      "['Mark', 'Taylor', 'Employee']\n",
      "Mark Taylor\n",
      "Employee\n",
      "['Mark', 'Whitt', 'N/A']\n",
      "Mark Whitt\n",
      "N/A\n",
      "['Martin', 'Cuilla', 'Manager']\n",
      "Martin Cuilla\n",
      "Manager\n",
      "['Mary', 'Fischer', 'Employee']\n",
      "Mary Fischer\n",
      "Employee\n",
      "['Matthew', 'Lenhart', 'Employee']\n",
      "Matthew Lenhart\n",
      "Employee\n",
      "['Matthew', 'Motley', 'Director']\n",
      "Matthew Motley\n",
      "Director\n",
      "['xxx']\n",
      "['John', 'Forney', 'Manager', 'Real', 'time', 'Trading', 'Desk']\n",
      "John Forney\n",
      "Manager Real time Trading Desk\n",
      "['Michelle', 'Lokay', 'Employee', 'Administrative', 'Asisstant']\n",
      "Michelle Lokay\n",
      "Employee Administrative Asisstant\n",
      "['Michelle', 'Cash', 'N/A']\n",
      "Michelle Cash\n",
      "N/A\n",
      "['Michelle', 'Lokay', 'Employee', 'Administrative', 'Asisstant']\n",
      "Michelle Lokay\n",
      "Employee Administrative Asisstant\n",
      "['Mike', 'Carson', 'Manager']\n",
      "Mike Carson\n",
      "Manager\n",
      "['Michael', 'Grigsby', 'Manager']\n",
      "Michael Grigsby\n",
      "Manager\n",
      "['Michael', 'Maggi', 'Director']\n",
      "Michael Maggi\n",
      "Director\n",
      "['xxx']\n",
      "['Mike', 'Swerzbin', 'Trader']\n",
      "Mike Swerzbin\n",
      "Trader\n",
      "['Phillip', 'Love', 'N/A']\n",
      "Phillip Love\n",
      "N/A\n",
      "['Monika', 'Causholli', 'Employee', 'Analyst', 'Risk', 'Management']\n",
      "Monika Causholli\n",
      "Employee Analyst Risk Management\n",
      "['xxx']\n",
      "['Kevin', 'Presto', 'Vice', 'President']\n",
      "Kevin Presto\n",
      "Vice President\n",
      "['Susan', 'Scott', 'N/A']\n",
      "Susan Scott\n",
      "N/A\n",
      "['xxx']\n",
      "['Jane', 'Tholt', 'Vice', 'President']\n",
      "Jane Tholt\n",
      "Vice President\n",
      "['Patrice', 'Mims', 'N/A']\n",
      "Patrice Mims\n",
      "N/A\n",
      "['Paul', 'Thomas', 'N/A']\n",
      "Paul Thomas\n",
      "N/A\n",
      "['broadcast', 'proxy']\n",
      "broadcast proxy\n",
      "\n",
      "['Peter', 'Keavey', 'Employee']\n",
      "Peter Keavey\n",
      "Employee\n",
      "['Philip', 'Allen', 'Manager']\n",
      "Philip Allen\n",
      "Manager\n",
      "['Phillip', 'Love', 'N/A']\n",
      "Phillip Love\n",
      "N/A\n",
      "['Phillip', 'Platter', 'Employee', 'Sr.Specialist']\n",
      "Phillip Platter\n",
      "Employee Sr.Specialist\n",
      "['Randall', 'Gay', 'N/A']\n",
      "Randall Gay\n",
      "N/A\n",
      "['Richard', 'Ring', 'Employee']\n",
      "Richard Ring\n",
      "Employee\n",
      "['Richard', 'Sanders', 'Vice', 'President', 'Enron', 'WholeSale', 'Services']\n",
      "Richard Sanders\n",
      "Vice President Enron WholeSale Services\n",
      "['Richard', 'Shapiro', 'Vice', 'President', 'Regulatory', 'Affairs']\n",
      "Richard Shapiro\n",
      "Vice President Regulatory Affairs\n",
      "['Rick', 'Buy', 'Manager', 'Chief', 'Risk', 'Management', 'Officer']\n",
      "Rick Buy\n",
      "Manager Chief Risk Management Officer\n",
      "['Robert', 'Badeer', 'Director']\n",
      "Robert Badeer\n",
      "Director\n",
      "['Robert', 'Benson', 'Director']\n",
      "Robert Benson\n",
      "Director\n",
      "['xxx']\n",
      "['Rod', 'Hayslett', 'Vice', 'President', 'Also', 'Chief', 'Financial', 'Officer', 'and', 'Treasurer']\n",
      "Rod Hayslett\n",
      "Vice President Also Chief Financial Officer and Treasurer\n",
      "['Ryan', 'Slinger', 'Trader']\n",
      "Ryan Slinger\n",
      "Trader\n",
      "['Sally', 'Beck', 'Employee', 'Chief', 'Operating', 'Officer']\n",
      "Sally Beck\n",
      "Employee Chief Operating Officer\n",
      "['Sandra', 'Brawner', 'Director']\n",
      "Sandra Brawner\n",
      "Director\n",
      "['xxx']\n",
      "['xxx']\n",
      "['Scott', 'Neal', 'Vice', 'President']\n",
      "Scott Neal\n",
      "Vice President\n",
      "['Shelley', 'Corman', 'Vice', 'President', 'Regulatory', 'Affairs']\n",
      "Shelley Corman\n",
      "Vice President Regulatory Affairs\n",
      "['Hunter', 'Shively', 'Vice', 'President']\n",
      "Hunter Shively\n",
      "Vice President\n",
      "['Stacy', 'Dickson', 'Employee']\n",
      "Stacy Dickson\n",
      "Employee\n",
      "['Stanley', 'Horton', 'President', 'Enron', 'Gas', 'Pipeline']\n",
      "Stanley Horton\n",
      "President Enron Gas Pipeline\n",
      "['Stephanie', 'Panus', 'Employee']\n",
      "Stephanie Panus\n",
      "Employee\n",
      "['Steven', 'Kean', 'Vice', 'President', 'Vice', 'President', '&', 'Chief', 'of', 'Staff']\n",
      "Steven Kean\n",
      "Vice President Vice President & Chief of Staff\n",
      "['xxx']\n",
      "['Susan', 'Bailey', 'N/A']\n",
      "Susan Bailey\n",
      "N/A\n",
      "['Susan', 'Pereira', 'Employee']\n",
      "Susan Pereira\n",
      "Employee\n",
      "['Susan', 'Scott', 'N/A']\n",
      "Susan Scott\n",
      "N/A\n",
      "['Kim', 'Ward', 'N/A']\n",
      "Kim Ward\n",
      "N/A\n",
      "['Tana', 'Jones', 'N/A']\n",
      "Tana Jones\n",
      "N/A\n",
      "['Teb', 'Lokey', 'Manager', 'Regulatory', 'Affairs']\n",
      "Teb Lokey\n",
      "Manager Regulatory Affairs\n",
      "['Theresa', 'Staab', 'Employee']\n",
      "Theresa Staab\n",
      "Employee\n",
      "['John', 'Hodge', 'Managing', 'Director']\n",
      "John Hodge\n",
      "Managing Director\n",
      "['Thomas', 'Martin', 'Vice', 'President']\n",
      "Thomas Martin\n",
      "Vice President\n",
      "['Paul', 'Lucci', 'Employee']\n",
      "Paul Lucci\n",
      "Employee\n",
      "['Tom', 'Donohoe', 'N/A']\n",
      "Tom Donohoe\n",
      "N/A\n",
      "['Tori', 'Kuykendall', 'Trader']\n",
      "Tori Kuykendall\n",
      "Trader\n",
      "['Tracy', 'Geaccone', 'Employee']\n",
      "Tracy Geaccone\n",
      "Employee\n",
      "['Vince', 'Kaminski', 'Manager', 'Risk', 'Management', 'Head']\n",
      "Vince Kaminski\n",
      "Manager Risk Management Head\n",
      "['Vladi', 'Pimenov', 'N/A']\n",
      "Vladi Pimenov\n",
      "N/A\n",
      "['Charles', 'Weldon', 'N/A']\n",
      "Charles Weldon\n",
      "N/A\n",
      "['David', 'Delainey', 'CEO', 'Enron', 'North', 'America', 'and', 'Enron', 'Enery', 'Services']\n",
      "David Delainey\n",
      "CEO Enron North America and Enron Enery Services\n",
      "['Susan', 'Pereira', 'Employee']\n",
      "Susan Pereira\n",
      "Employee\n",
      "['Stacey', 'White', 'N/A']\n",
      "Stacey White\n",
      "N/A\n",
      "['\"albert.meyers\"', '\"a..martin\"', '\"andrea.ring\"', '\"andrew.lewis\"', '\"andy.zipper\"', '\"a..shankman\"', '\"barry.tycholiz\"', '\"benjamin.rogers\"', '\"bill.rapp\"', '\"bill.williams\"', '\"brad.mckay\"', '\"brenda.whitehead\"', '\"b..sanders\"', '\"cara.semperger\"', '\"c..giron\"', '\"charles.weldon\"', '\"chris.dorland\"', '\"chris.germany\"', '\"clint.dean\"', '\"cooper.richey\"', '\"craig.dean\"', '\"dana.davis\"', '\"dan.hyvl\"', '\"danny.mccarty\"', '\"daren.farmer\"', '\"darrell.schoolcraft\"', '\"darron.giron\"', '\"david.delainey\"', '\"debra.bailey\"', '\"debra.perlingiere\"', '\"diana.scholtes\"', '\"d..martin\"', '\"don.baughman\"', '\"drew.fossum\"', '\"d..steffes\"', '\"d..thomas\"', '\"dutch.quigley\"', '\"e..haedicke\"', '\"elizabeth.sager\"', '\"eric.bass\"', '\"eric.saibi\"', '\"errol.mclaughlin\"', '\"e.taylor\"', '\"f..brawner\"', '\"f..campbell\"', '\"f..keavey\"', '\"fletcher.sturm\"', '\"frank.ermis\"', '\"geir.solberg\"', '\"geoff.storey\"', '\"gerald.nemec\"', '\"greg.whalley\"', '\"gretel.smith\"', '\"harry.arora\"', '\"h..lewis\"', '\"holden.salisbury\"', '\"hunter.shively\"', '\"james.derrick\"', '\"james.steffes\"', '\"jane.tholt\"', '\"jason.williams\"', '\"jason.wolfe\"', '\"jay.reitmeyer\"', '\"jeff.dasovich\"', '\"jeff.king\"', '\"jeffrey.hodge\"', '\"jeffrey.shankman\"', '\"jeff.skilling\"', '\"j..farmer\"', '\"j.harris\"', '\"jim.schwieger\"', '\"j..kaminski\"', '\"j.kaminski\"', '\"j..kean\"', '\"joannie.williamson\"', '\"joe.parks\"', '\"joe.quenet\"', '\"joe.stepenovitch\"', '\"john.arnold\"', '\"john.forney\"', '\"john.griffith\"', '\"john.hodge\"', '\"john.lavorato\"', '\"john.zufferli\"', '\"jonathan.mckay\"', '\"j..sturm\"', '\"juan.hernandez\"', '\"judy.hernandez\"', '\"judy.townsend\"', '\"k..allen\"', '\"kam.keiser\"', '\"kate.symes\"', '\"kay.mann\"', '\"keith.holst\"', '\"kenneth.lay\"', '\"kevin.hyatt\"', '\"kevin.presto\"', '\"kevin.ruscitti\"', '\"kimberly.watson\"', '\"kim.ward\"', '\"larry.campbell\"', '\"larry.may\"', '\"l..gay\"', '\"lindy.donoho\"', '\"lisa.gang\"', '\"liz.taylor\"', '\"l..mims\"', '\"louise.kitchen\"', '\"lynn.blair\"', '\"margaret.carson\"', '\"marie.heard\"', '\"mark.e.haedicke\"', '\"mark.haedicke\"', '\"mark.mcconnell\"', '\"mark.taylor\"', '\"mark.whitt\"', '\"martin.cuilla\"', '\"mary.fischer\"', '\"matthew.lenhart\"', '\"matt.motley\"', '\"matt.smith\"', '\"m..forney\"', '\"michele.lokay\"', '\"michelle.cash\"', '\"michelle.lokay\"', '\"mike.carson\"', '\"mike.grigsby\"', '\"mike.maggi\"', '\"mike.mcconnell\"', '\"mike.swerzbin\"', '\"m..love\"', '\"monika.causholli\"', '\"monique.sanchez\"', '\"m..presto\"', '\"m..scott\"', '\"m..smith\"', '\"m..tholt\"', '\"patrice.mims\"', '\"paul.thomas\"', '\"peter.keavey\"', '\"phillip.allen\"', '\"phillip.love\"', '\"phillip.platter\"', '\"randall.gay\"', '\"richard.ring\"', '\"richard.sanders\"', '\"richard.shapiro\"', '\"rick.buy\"', '\"robert.badeer\"', '\"robert.benson\"', '\"rob.gay\"', '\"rod.hayslett\"', '\"ryan.slinger\"', '\"sally.beck\"', '\"sandra.brawner\"', '\"sara.shackleton\"', '\"scott.hendrickson\"', '\"scott.neal\"', '\"shelley.corman\"', '\"s..shively\"', '\"stacy.dickson\"', '\"stanley.horton\"', '\"stephanie.panus\"', '\"steven.kean\"', '\"steven.south\"', '\"susan.bailey\"', '\"susan.pereira\"', '\"susan.scott\"', '\"s..ward\"', '\"tana.jones\"', '\"teb.lokey\"', '\"theresa.staab\"', '\"t..hodge\"', '\"thomas.martin\"', '\"t..lucci\"', '\"tom.donohoe\"', '\"tori.kuykendall\"', '\"tracy.geaccone\"', '\"vince.kaminski\"', '\"vladi.pimenov\"', '\"v.weldon\"', '\"w..delainey\"', '\"w..pereira\"', '\"w..white\"', '\"role\"']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "path_to_roles='data/ENRON/roles_enron.txt'\n",
    "handle_map=open(path_to_roles);\n",
    "map_name2role={}\n",
    "dict_role={}\n",
    "it=0\n",
    "for line in handle_map:\n",
    "    line=line.strip(\"\\n\")\n",
    "    lst=line.split(\"\\t\")\n",
    "    if it<10:\n",
    "        print lst\n",
    "    email=lst[0].lower()\n",
    "    rest=lst[1].split()\n",
    "    print rest\n",
    "    try:\n",
    "        name=rest[0]+\" \"+rest[1]\n",
    "        title=\"\"\n",
    "        for j in range(2,len(rest)):\n",
    "            title+=rest[j]+\" \"\n",
    "        title=title.rstrip(\" \")\n",
    "        print name\n",
    "        map_name2role[name]=title\n",
    "        try:\n",
    "            dict_role[title].append(name)\n",
    "        except:\n",
    "            dict_role[title]=[]\n",
    "            dict_role[title].append(name)\n",
    "        print title\n",
    "    except:\n",
    "        pass\n",
    "    it+=1\n",
    "\n",
    "\n",
    "path_to_edges='data/ENRON/data.txt'\n",
    "handle_edges=open(path_to_edges);\n",
    "edge_list=[]\n",
    "for line in handle_edges:\n",
    "    line=line.strip(\"\\n\")\n",
    "    lst=line.split(\" \")\n",
    "    \n",
    "    time=lst[0]\n",
    "    src=lst[1]\n",
    "    dest=lst[2]\n",
    "    edge_list.append((src,dest))\n",
    "    \n",
    "\n",
    "Enron_graph=nx.from_edgelist(edge_list)\n",
    "Enron_adj=nx.adjacency_matrix(Enron_graph).todense()\n",
    "\n",
    "path_to_adj='data/ENRON/data.txt'\n",
    "handle_edges=open(path_to_adj);\n",
    "edge_list=[]\n",
    "it=0\n",
    "N=184\n",
    "titles=[]\n",
    "for line in handle_edges:\n",
    "    line=line.strip(\"\\n\")\n",
    "    lst=line.split()\n",
    "    if it==0:\n",
    "        print lst\n",
    "        adj=pd.DataFrame(np.zeros((N,N)),index=lst[:-1])\n",
    "        adj.columns=lst[:-1]\n",
    "    else:\n",
    "        for i in range(N):\n",
    "            adj.iloc[it-1,i]=int(lst[i+1])\n",
    "        title=\"\"\n",
    "        for j in range(185,len(lst)):\n",
    "            title+=lst[j]+\" \"\n",
    "        title=title.rstrip(\" \")   \n",
    "        \n",
    "        titles.append(title)\n",
    "    it+=1\n",
    "Graph_enron=nx.from_numpy_matrix(adj.as_matrix())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Create the labels\n",
    "\n",
    "Stores the labels as \"colors\".\n",
    "Note that we decide to regroup the \"in-house lawyer\" (unique representent of his class) with the NA category. To create more balanced classes, we also regroup the \"Managing Directors\" with the Directors (consistent our research on the different titles: Managing Director seems to refer to a category of directors, and is thus above manager)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors_map={}\n",
    "colors_gen_map={}\n",
    "N=len(map_name2role)\n",
    "new_color=0\n",
    "new_color_gen=0\n",
    "colors=[]\n",
    "map2shortTitle={}\n",
    "it=0\n",
    "for i in range(len(titles)):\n",
    "    t=titles[i]\n",
    "    try:\n",
    "        colors_map[t][1]+=1\n",
    "    except:\n",
    "        colors_map[t]=[new_color,1]\n",
    "        new_color+=1\n",
    "    \n",
    "    lst=titles[i].replace(\",\", \"\")\n",
    "    lst=lst.replace('\"', \"\")\n",
    "    lst=lst.split()\n",
    "    indice=lst[0][:3]\n",
    "    try:    \n",
    "        colors_gen_map[lst[0]][1]+=[i]\n",
    "        map2shortTitle[lst[0]].append(i)\n",
    "    except:\n",
    "        colors_gen_map[lst[0]]=[new_color_gen,[i]]\n",
    "        new_color_gen+=1\n",
    "        map2shortTitle[lst[0]]=[i]\n",
    "    colors.append(colors_gen_map[lst[0]][0])\n",
    " \n",
    "\n",
    "## to allow more balance between class, we regroup classes that are \"approximatively the same\":\n",
    "colors=[c if c!=8 else 3 for c in colors]## managing director to director\n",
    "colors=[c if c!=9 else 2 for c in colors] ## inhouse lawyer to NA\n",
    "nb_roles=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30  people in category  Vice\n",
      "5  people in category  CEO\n",
      "55  people in category  NA\n",
      "11  people in category  Trader\n",
      "20  people in category  Director\n",
      "17  people in category  Manager\n",
      "41  people in category  Employee\n",
      "5  people in category  President\n"
     ]
    }
   ],
   "source": [
    "for k in colors_gen_map.keys():\n",
    "    nb_people=np.sum([c==colors_gen_map[k][0] for c in colors])\n",
    "    if nb_people>0:\n",
    "        print np.sum([c==colors_gen_map[k][0] for c in colors]), ' people in category ', k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Employee', 1: 'Vice', 2: 'NA', 3: 'Director', 4: 'President', 5: 'Manager', 6: 'Trader', 7: 'CEO', 8: 'Managing', 9: 'In'}\n"
     ]
    }
   ],
   "source": [
    "## Define the inverse mapping from label to employee title\n",
    "tent={v[0]:k for k,v in colors_gen_map.iteritems()}\n",
    "print tent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Check properties of the induced network\n",
    "\n",
    "We here check a few properties for the network. In particular, it seems that the 'raw' network is in fact constituted of  disconnected components (2 loneley nodes). We thus get rid of these nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of connected components 3\n",
      "component  1  with  182  nodes  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183]\n",
      "component  2  with  1  nodes  [71]\n",
      "component  3  with  1  nodes  [117]\n"
     ]
    }
   ],
   "source": [
    "print \"number of connected components\",nx.number_connected_components(Graph_enron)\n",
    "it_k=1\n",
    "for Gg in nx.connected_component_subgraphs(Graph_enron):\n",
    "    print 'component ', it_k, ' with ', Gg.number_of_nodes(), ' nodes ', Gg.nodes()\n",
    "    it_k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A=nx.adjacency_matrix(Graph_enron).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(A,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "indices=range(A.shape[0])\n",
    "indices.pop(117)\n",
    "indices.pop(71)\n",
    "print len(indices)\n",
    "G=nx.from_numpy_matrix(A[indices,:][:, indices])\n",
    "colors=np.array(colors)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_connected_components(G)  # to double check that our induced graph is now connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Start the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-31 19:15:33,983:[WARNING](pygsp.graphs.gutils.check_weights): GSP_TEST_WEIGHTS: The main diagonal of the weight matrix is not 0!\n",
      "2017-10-31 19:15:34,041:[WARNING](pygsp.graphs.graph.__init__): Graph is not connected!\n",
      "2017-10-31 19:15:34,199:[WARNING](pygsp.graphs.gutils.check_weights): GSP_TEST_WEIGHTS: The main diagonal of the weight matrix is not 0!\n",
      "2017-10-31 19:15:34,262:[WARNING](pygsp.graphs.graph.__init__): Graph is not connected!\n",
      "2017-10-31 19:15:34,266:[INFO](pygsp.filters.filter.__init__): Heat : has to compute lmax\n",
      "2017-10-31 19:15:34,270:[INFO](pygsp.filters.filter.analysis): The analysis method is cheby\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e78b2d96cca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheat_print\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraphwave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGraph_enron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/Dropbox/GraphWave/graphwave.py\u001b[0m in \u001b[0;36mgraphwave\u001b[0;34m(G, taus, t, type_graph, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtaus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtaus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msmax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m### Compute the heat wavelets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mheat_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheat_diffusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtaus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiff_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"immediate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mchi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeaturize_characteristic_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheat_print\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheat_print\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/Dropbox/GraphWave/heat_diffusion.pyc\u001b[0m in \u001b[0;36mheat_diffusion\u001b[0;34m(G, taus, diff_type, b, type_graph)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mSf_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### creates the associated heat wavelets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mSf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSf_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSf_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m  \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/anaconda/lib/python2.7/site-packages/pygsp/filters/filter.pyc\u001b[0m in \u001b[0;36manalysis\u001b[0;34m(self, s, method, cheb_order, lanczos_order, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_lmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mcheb_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_filtering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_cheby_coeff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheb_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_filtering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheby_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheb_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/anaconda/lib/python2.7/site-packages/pygsp/utils.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cdonnat/anaconda/lib/python2.7/site-packages/pygsp/operators/fast_filtering.pyc\u001b[0m in \u001b[0;36mcompute_cheby_coeff\u001b[0;34m(f, m, N, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmpN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         c[o] = 2. / N * np.dot(f.g[i](a1 * num + a2),\n\u001b[0m\u001b[1;32m     53\u001b[0m                                   np.cos(np.pi * o * (tmpN + 0.5) / N))\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "chi,heat_print, taus=graphwave(Graph_enron, 'optimal', t=list(np.arange(0,200,0.5)), verbose=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ami=sk.metrics.adjusted_mutual_info_score(colors, labels_pred)  \n",
    "sil=sk.metrics.silhouette_score(trans_data,labels_pred, metric='euclidean')\n",
    "ch=sk.metrics.calinski_harabaz_score(trans_data, labels_pred)\n",
    "hom=sk.metrics.homogeneity_score(colors, labels_pred) \n",
    "comp=sk.metrics.completeness_score(colors, labels_pred)\n",
    "print 'Homogeneity \\t Completeness \\t AMI \\t nb clusters \\t CH \\t  Silhouette \\n'\n",
    "print str(hom)+'\\t'+str(comp)+'\\t'+str(ami)+'\\t'+str(nb_clust)+'\\t'+str(ch)+'\\t'+str(sil)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "ag=sk.cluster.KMeans(n_clusters=2)\n",
    "ag.fit(chi)\n",
    "print(len(labels_pred))\n",
    "labels_pred=ag.labels_\n",
    "ami=sk.metrics.adjusted_mutual_info_score(np.array(grp), labels_pred)  \n",
    "sil=sk.metrics.silhouette_score(chi,labels_pred, metric='euclidean')\n",
    "ch=sk.metrics.calinski_harabaz_score(chi, labels_pred)\n",
    "hom=sk.metrics.homogeneity_score(np.array(grp), labels_pred) \n",
    "comp=sk.metrics.completeness_score(np.array(grp), labels_pred)\n",
    "print hom, comp,sil\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous plot shows the different classes (each associated to a particular symbol), and the colors correspond to the different groups recovered by kmeans. The first thing that we observe is that this clustering is a little messier than before: as what was to be expected, the classes overlap, and our algorithms struggle to clearly separate the classes. Note also how struc2vec consists of one dense cluster, and a few outliers. RoleX and GraphWave achieve better separation by putting more distances between different points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Quantitative analysis: Purity of the k nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by looking at how well the algorithms perform with respect to the \"purity\" of the nearest neighbors. That is, looking for each node at its $k$ nearest neighbors, what is the number of neighbors that are from the same class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the average purities. We note that the nearest neighbor purity is higher for GraphWave. However, as we increase\n",
    "the depth of the neighborhood search, the purities for the other two algorithms start performing  well. This might also be due to the fact that these algorithms tend to cluster everyone together-- all the embeddings have very close PCA projections on the first 2 principal axes, which can potentially yield higher purity, especially in classes with a high number of samples. GraphWave, on the other hand, puts more distance between embeddings, and tries to learn a \"spectrum\" of roles. \n",
    "\n",
    "As such, this metric might however be only telling part of the story. Roles in companies are not neatly defined, so we should not expect all traders to be close to only traders, etc. However, we do expect traders to be generally closer as a class than to the other classes.  A correct characterization of the algorithms' performance is thus how, in average, clases are clustered together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Quantitative analysis of the results: coherence of the clusters\n",
    "\n",
    "\n",
    "The goal of this subsection is to assess the algorithms's performances from a quantitative point of view. In particular, we need to assess the relative densities of the classes, and how well the algorithm is able to separate the different classes.\n",
    "\n",
    "To this end, we look at different metrics:\n",
    "+ the F-statistics, described in the synthetic experiments sheet. This metric evaluates the realtive contrasts between clusters (the higher the better)\n",
    "+ The median variance of each class (the lower the better)\n",
    "+ The overall performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Perf_tot=pd.DataFrame(np.zeros(Perf[0].shape),index=Perf[0].index, columns=Perf[0].columns)\n",
    "for k in Perf.keys():\n",
    "    Perf_tot+=1.0/len(Perf.keys())*Perf[k]\n",
    "\n",
    "meanF={k: np.mean(Ff[k]) for k in Ff.keys()}\n",
    "meanVar={k: np.mean(Varr[k]) for k in Varr.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Algorithm \\t Median W-variance \\t  F statistics \\n\"\n",
    "for k  in meanF.keys():\n",
    "    print k,\"\\t\", meanVar[k], '\\t',  meanF[k], \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the different constrasts between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrast\n",
    "\n",
    "We look at the contrast between different categories, that is, for each cluster $i$ and $j$, tje contrast between $i$ and $j$ with respect to $i$ defined as:\n",
    "    $$\\text{Contrast}(C_i, C_j)=\\frac{d(C_i, C_{j})^2}{d(C_i,C_i)^2} \\quad (*)$$ \n",
    "The idea is to assess the potential overlap between the clusters. Ideally, if the algorithm can separate the classes well, this ratio should be big. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Relevant contrast\n",
    "R2={k:[] for k in D_var[0].keys()}\n",
    "for i in Perf.keys():\n",
    "    for k in D_var[0].keys():\n",
    "        R2[k].append(1.0/(8*(8-1))*np.sum(np.diag(1.0/np.diag(D_var[i][k])).dot(D_var[i][k])>4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Method  \\t  avg Contrast Std.  \\t avg Contrast Mean \\n'\n",
    "for k in D_var[0].keys():\n",
    "    print k, ': \\t',np.mean(np.std([np.diag(1.0/np.diag(D_var[i][k].iloc[true_classes,true_classes])).dot(D_var[i][k].iloc[true_classes,true_classes]) for i in D_var.keys()]).reshape((-1,1))/np.mean([np.diag(1.0/np.diag(D_var[i][k].iloc[true_classes,true_classes])).dot(D_var[i][k].iloc[true_classes,true_classes] ) for i in D_var.keys()]).reshape((-1,1))),\\\n",
    "    '\\t',np.mean([np.mean(np.diag(1.0/np.sqrt(np.diag(D_var[i][k].iloc[true_classes,true_classes]))).dot(D_var[i][k].iloc[true_classes,true_classes].dot(np.diag(1.0/np.sqrt(np.diag(D_var[i][k].iloc[true_classes,true_classes]))))))\\\n",
    "                                for i in D_var.keys()]),' \\n'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.diag(1.0/np.diag(D_classes[0]['chi7'])).dot(D_classes[0]['chi7']).reshape((-1,1)),bins=10,color='red', label='chi7')\n",
    "plt.hist(np.diag(1.0/np.diag(D_classes[0]['chi_opt2'])).dot(D_classes[0]['chi_opt2']).reshape((-1,1)),bins=10,color='blue', label='chi_opt2')\n",
    "plt.hist(np.diag(1.0/np.diag(D_classes[0]['RoleX'])).dot(D_classes[0]['RoleX']).reshape((-1,1)),bins=10,color='green', label='RoleX')\n",
    "plt.hist(np.diag(1.0/np.diag(D_classes[0]['struc2vec'])).dot(D_classes[0]['struc2vec']).reshape((-1,1)),bins=10,color='pink', label='struc2vec')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of the relative contrasts recovered by each method (all classes including NA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.diag(1.0/np.diag(D_var[0]['chi7'].iloc[true_classes,true_classes])).dot(D_var[0]['chi7'].iloc[true_classes,true_classes]).reshape((-1,1)),bins=10,color='red',label='chi7')\n",
    "plt.hist(np.diag(1.0/np.diag(D_var[0]['chi_opt2'].iloc[true_classes,true_classes])).dot(D_var[0]['chi_opt2'].iloc[true_classes,true_classes]).reshape((-1,1)),bins=10,color='blue',label='chi_opt2')\n",
    "plt.hist(np.diag(1.0/np.diag(D_var[0]['RoleX'].iloc[true_classes,true_classes])).dot(D_var[0]['RoleX'].iloc[true_classes,true_classes]).reshape((-1,1)),bins=10,color='green',label='RoleX')\n",
    "plt.hist(np.diag(1.0/np.diag(D_var[0]['struc2vec'].iloc[true_classes,true_classes])).dot(D_var[0]['struc2vec'].iloc[true_classes,true_classes]).reshape((-1,1)),bins=10,color='pink',label='struc2vec')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of the relative contrasts recovered by each method (true classes, without NA)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also evaluate (visually) these contrasts via heatmap. Note the high variability of struc2vec's \"within distance\" (that is d(C_i,C_i) with respect to the average square distances to the other classes. This is consistent with the overlap that we observe when computing the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in ['RoleX','struc2vec','chi0','chi7','chi_opt2']:\n",
    "    Matrix=pd.DataFrame((np.diag(1.0/np.sqrt(np.diag(D_var[0][k])))).dot(D_var[0][k].dot(np.diag(1.0/np.sqrt(np.diag(D_var[0][k]))))),\\\n",
    "       index=[tent[j] for j in range(8)],columns=[tent[j] for j in range(8)])\n",
    "    plt.figure()\n",
    "    sb.heatmap(Matrix)\n",
    "    plt.title('Contrast heatmap: average square distance between classes relative to the variability of the classes for '+k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "order_cat=['Employee','Trader','Manager','Director','Vice','President','CEO']\n",
    "categories=[(k,v[0]) for k,v in colors_gen_map.iteritems()]\n",
    "\n",
    "order=np.argsort([categories[i][1] for i in range(len(categories))])\n",
    "index=[categories[o][0] for o in order]\n",
    "index=[index[i] for i in range(len(index)) if i!=2 and i!=9 and i!=8]\n",
    "\n",
    "\n",
    "\n",
    "for k in ['struc2vec','RoleX','chi0','chi_opt2']:\n",
    "    fig, ax = plt.subplots(figsize=(4,3))\n",
    "    sb.set_context(\"paper\", font_scale=1.5)           \n",
    "    sb.heatmap(D_classes[1][k].loc[order_cat,order_cat],cmap='PiYG');\n",
    "    plt.title('heatmap for '+k)\n",
    "    #plt.savefig(\"plots/heatmap\"+k+\"Enron.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Quantitative analysis of the results: Hierarchy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to assess if the methods recover some structure in the hierachy of the company. The single classes might be too small and too noisy to get meaningful results, but we aggregate them into different larger classes according to their proximity in the hieraachy. In particular, we group CE0 with Presidents, and the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define two groups: the \"top hierarchy\" (CEO +Vice president) vs the rest of the hierarchy\n",
    "grp=[1 if colors[i] in [7,4] else 2 for i in range(G.number_of_nodes())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "nb_clust=len(np.unique(colors))\n",
    "pca=PCA(n_components=5)\n",
    "trans_data=pca.fit_transform(StandardScaler().fit_transform(chi))\n",
    "km=sk.cluster.KMeans(n_clusters=nb_clust)\n",
    "km.fit(chi)\n",
    "labels_pred=km.labels_\n",
    "######## Params for plotting\n",
    "cmapx=plt.get_cmap('rainbow')\n",
    "x=np.linspace(0,1,np.max(labels_pred)+1)\n",
    "col=[cmapx(xx) for xx in x ]\n",
    "markers = {0:'*',1: '.', 2:',',3: 'o',4: 'v',5: '^',6: '<',7: '>',8: 3 ,9:'d',10: '+',11:'x',12:'D',13: '|',14: '_',15:4,16:0,17:1,18:2,19:6,20:7}\n",
    "########\n",
    "## Define two groups: the \"top hierarchy\" (CEO +Vice president) vs the rest of the hierarchy\n",
    "grp=[1 if colors[i] in [7,4] else 2 for i in range(G.number_of_nodes())]\n",
    "for c in np.unique(colors):\n",
    "        indc=[i for i,x in enumerate(colors) if x==c]\n",
    "        #print indc\n",
    "        plt.scatter(trans_data[indc,0], trans_data[indc,1],c=np.array(col)[list(np.array(labels_pred)[indc])] ,marker=markers[c%len(markers)],s=500)\n",
    "labels = colors\n",
    "for label,c, x, y in zip(labels,labels_pred, trans_data[:, 0], trans_data[:, 1]):\n",
    "            plt.annotate(label,xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
