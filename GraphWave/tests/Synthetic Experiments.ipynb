{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Perturbation Analysis </h1> </center>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "In this notebook, we investigate the  ability of the **GraphWave** algorithm to detect structural similarities, as well as its robustness to small perturbations. We propose an analysis of the accuracy of the recovery of the different topological roles based on simulations on toy graphs, so that we benefit from an actual ground-truth to benchmark the different results. For convenience purposes, this notebook contains code for running the \"perturbed\" experiments provided in the associated paper. We have tested here \"small pertubations\" (we randomly add a few edges to the structure, so as to  maintain the patterns (this is why we did not delete edges as well), but shattering the symmetry of the system that yielded structural equivalents. For simulations with a higher noise level, we refer the reader to Notebook Synthetic Experiments--structures.\n",
    "\n",
    "The setup of the experiment is the following:\n",
    "\n",
    "1. We begin by creating a toy graph (that is, a regular structure with repetitions of identical patterns at different areas of the graph). Each type of structural role (that is, bottom corner in the house shape, middle of the center ring, etc.) is endowed with a particular label.\n",
    "2. __Optional__: to simulate the effect of small perturbations, we artificially remove and add a few edges on the graph\n",
    "3. We compute the structural representations given by our method\n",
    "4. To assess the relevance of our results, we propose to evaluate our method using 3 different criteria:\n",
    "    + We project these representations in 2D using PCA: the idea is to try to assess visually the proximity of the different featurization. In the different plots,\n",
    "    + We also plug-in these representations as input into a clustering algorithm (default: kmeans), and assess the purity of the clusters that are recovered using k-means. This gives us an indicator of the relevance of our embeddings if the goal was to recover $K$ distinct classes of structural equivalents.\n",
    "\n",
    "\n",
    "First of all, to provide a little bit of intuition and to explain some of the follwoing results, we note that RoleX is specifically designed for clustering role similarities, whereas struc2vec and GraphWave aim to find similarities across a spectrum of roles (hence the distance between nodes is more meaningful in the later than in the case of RoleX), which does not guarantee to provide comparisons across classes. Hence, since we propose to assess the performance via clustering, RoleX should perform better --it was designed specifically for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Loading the modules and creating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import networkx as nx \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os,sys\n",
    "sys.path.append( '../../../GraphWave/')\n",
    "from graphwave import *\n",
    "dirpath_default=os.getcwd()\n",
    "from distances.distances_between_graphs import *\n",
    "from distances.distances_signature import *\n",
    "from shapes.shapes import *\n",
    "\n",
    "from utils.graph_tools  import *\n",
    "from utils import *\n",
    "\n",
    "from performance_evaluation.performance_evaluation import *\n",
    "from performance_evaluation.purity import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1- Start by defining our favorite regular structure\n",
    "\n",
    "width_basis=15\n",
    "nbTrials=20\n",
    "\n",
    "\n",
    "################################### EXAMPLE TO BUILD A SIMPLE REGULAR STRUCTURE ##########\n",
    "## REGULAR STRUCTURE: the most simple structure:  basis + n small patterns of a single type\n",
    "\n",
    "### 1. Choose the basis (cycle, torus or chain)\n",
    "basis_type=\"cycle\" \n",
    "\n",
    "### 2. Add the shapes \n",
    "nb_shapes=5  ## numbers of shapes to add \n",
    "#shape=[\"fan\",6] ## shapes and their associated required parameters  (nb of edges for the star, etc)\n",
    "#shape=[\"star\",6]\n",
    "shape=[\"house\"]\n",
    "\n",
    "### 3. Give a name to the graph\n",
    "identifier='AA'  ## just a name to distinguish between different trials\n",
    "name_graph='houses'+ identifier\n",
    "sb.set_style('white')\n",
    "\n",
    "### 4. Pass all these parameters to the Graph Structure\n",
    "add_edges=4 ## nb of edges to add anywhere in the structure\n",
    "del_edges=0\n",
    "G,colors=build_regular_structure(width_basis,basis_type, nb_shapes,shape, start=0,add_random_edges=add_edges,plot=True,savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'nb of nodes in the graph: ', G.number_of_nodes()\n",
    "print 'nb of edges in the graph: ', G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the analysis!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first set of experiments, we look at the performance of the algorithms when 3 edges are randomly added to the structure. This provides a \"small perturbation\", since the Jaccard distance between the adjacency matrices of the two graphs is:\n",
    "$$ d_{HAmming}(A, \\tilde{A})=\\frac{||A -\\tilde{A}||_2}{||A +\\tilde{A}||_*}=\\frac{6}{63*2}=0.048$$\n",
    "\n",
    "We iterate the experiment 20 times, and average over the performance score to finally be able to compare the algorithms. \n",
    "\n",
    "We have included the results of this experiments in the cache folder, which the reader can either download or run again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirpath='../../GraphWave'\n",
    "chi,heat_print, taus=graphwave(G, 'automatic', verbose=True)\n",
    "mapping_inv={i: taus[i] for i in range(len(taus))}\n",
    "mapping={float(v): k for k,v in mapping_inv.iteritems()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "nb_clust=len(np.unique(colors))\n",
    "pca=PCA(n_components=5)\n",
    "trans_data=pca.fit_transform(StandardScaler().fit_transform(chi))\n",
    "km=sk.cluster.KMeans(n_clusters=nb_clust)\n",
    "km.fit(trans_data)\n",
    "labels_pred=km.labels_\n",
    "######## Params for plotting\n",
    "cmapx=plt.get_cmap('rainbow')\n",
    "x=np.linspace(0,1,np.max(labels_pred)+1)\n",
    "col=[cmapx(xx) for xx in x ]\n",
    "markers = {0:'*',1: '.', 2:',',3: 'o',4: 'v',5: '^',6: '<',7: '>',8: 3 ,9:'d',10: '+',11:'x',12:'D',13: '|',14: '_',15:4,16:0,17:1,18:2,19:6,20:7}\n",
    "########\n",
    "\n",
    "for c in np.unique(colors):\n",
    "        indc=[i for i,x in enumerate(colors) if x==c]\n",
    "        #print indc\n",
    "        plt.scatter(trans_data[indc,0], trans_data[indc,1],c=np.array(col)[list(np.array(labels_pred)[indc])] ,marker=markers[c%len(markers)],s=500)\n",
    "labels = colors\n",
    "for label,c, x, y in zip(labels,labels_pred, trans_data[:, 0], trans_data[:, 1]):\n",
    "            plt.annotate(label,xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ami=sk.metrics.adjusted_mutual_info_score(colors, labels_pred)  \n",
    "sil=sk.metrics.silhouette_score(trans_data,labels_pred, metric='euclidean')\n",
    "ch=sk.metrics.calinski_harabaz_score(trans_data, labels_pred)\n",
    "hom=sk.metrics.homogeneity_score(colors, labels_pred) \n",
    "comp=sk.metrics.completeness_score(colors, labels_pred)\n",
    "print 'Homogeneity \\t Completeness \\t AMI \\t nb clusters \\t CH \\t  Silhouette \\n'\n",
    "print str(hom)+'\\t'+str(comp)+'\\t'+str(ami)+'\\t'+str(nb_clust)+'\\t'+str(ch)+'\\t'+str(sil)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Varied shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "################################### EXAMPLE TO BUILD A MORE COMPLICATED STRUCTURE ##########\n",
    "######### Alternatively, to define a structure with different types of patterns, pass them as a list\n",
    "######### In the following example, we have 3 fans (with param. 6), 3 stars on 4 nodes, and 3 house shapes\n",
    "name_graph='regular'\n",
    "from sklearn import preprocessing\n",
    "width_basis=25\n",
    "add_edges=10\n",
    "list_shapes=[[\"fan\",6]]*5+[[\"star\",10]]*5+[[\"house\"]]*5 \n",
    "G,colors_shape, plugins,colors=build_structure(width_basis,basis_type,list_shapes, start=0,add_random_edges=add_edges,plot=False,savefig=False)\n",
    "nb_clust=len(np.unique(colors))\n",
    "chi,heat_print, taus=graphwave(G, 'automatic', verbose=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=5)\n",
    "trans_data=pca.fit_transform(StandardScaler().fit_transform(chi))\n",
    "km=sk.cluster.KMeans(n_clusters=nb_clust)\n",
    "km.fit(trans_data)\n",
    "labels_pred=km.labels_\n",
    "######## Params for plotting\n",
    "cmapx=plt.get_cmap('rainbow')\n",
    "x=np.linspace(0,1,np.max(labels_pred)+1)\n",
    "col=[cmapx(xx) for xx in x ]\n",
    "markers = {0:'*',1: '.', 2:',',3: 'o',4: 'v',5: '^',6: '<',7: '>',8: 3 ,9:'d',10: '+',11:'x',12:'D',13: '|',14: '_',15:4,16:0,17:1,18:2,19:6,20:7}\n",
    "########\n",
    "\n",
    "for c in np.unique(colors):\n",
    "        indc=[i for i,x in enumerate(colors) if x==c]\n",
    "        #print indc\n",
    "        plt.scatter(trans_data[indc,0], trans_data[indc,1],c=np.array(col)[list(np.array(labels_pred)[indc])] ,marker=markers[c%len(markers)],s=500)\n",
    "labels = colors\n",
    "for label,c, x, y in zip(labels,labels_pred, trans_data[:, 0], trans_data[:, 1]):\n",
    "            plt.annotate(label,xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "            \n",
    "\n",
    "ami=sk.metrics.adjusted_mutual_info_score(colors, labels_pred)  \n",
    "sil=sk.metrics.silhouette_score(trans_data,labels_pred, metric='euclidean')\n",
    "ch=sk.metrics.calinski_harabaz_score(trans_data, labels_pred)\n",
    "hom=sk.metrics.homogeneity_score(colors, labels_pred) \n",
    "comp=sk.metrics.completeness_score(colors, labels_pred)\n",
    "print 'Homogeneity \\t Completeness \\t AMI \\t nb clusters \\t CH \\t  Silhouette \\n'\n",
    "print str(hom)+'\\t'+str(comp)+'\\t'+str(ami)+'\\t'+str(nb_clust)+'\\t'+str(ch)+'\\t'+str(sil)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
